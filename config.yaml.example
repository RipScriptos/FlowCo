# FlowCo Configuration File Example
# Copy this file to config.yaml and customize as needed

ai:
  openai_api_key: null  # Set your OpenAI API key
  anthropic_api_key: null  # Set your Anthropic API key
  default_model: "gpt-3.5-turbo"
  use_local_models: false
  ollama_base_url: "http://localhost:11434"

database:
  path: "data/flowco.db"

web:
  host: "0.0.0.0"
  port: 12000
  debug: false

processing:
  max_image_size: 5242880  # 5MB
  supported_formats:
    - "jpg"
    - "jpeg"
    - "png"
    - "webp"

research:
  enable_web_scraping: true
  max_search_results: 10

# Logging configuration
logging:
  level: "INFO"
  file: "flowco.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Model-specific settings
models:
  openai:
    temperature: 0.7
    max_tokens: 2000
    timeout: 30
  
  anthropic:
    temperature: 0.7
    max_tokens: 2000
    timeout: 30
  
  ollama:
    temperature: 0.7
    num_predict: 2000
    timeout: 60

# Report generation settings
reports:
  default_format: "pdf"
  include_branding: true
  include_financial: true
  template_dir: "templates"
  output_dir: "reports"

# Cache settings (for production)
cache:
  enabled: false
  ttl: 3600  # 1 hour
  max_size: 1000